{
  "name": "Phase {{ phase }}: {{ backend|upper }} Consumer - {{ prompt_tokens }} tokens",
  "description": "{{ backend|upper }} Disaggregated Consumer, {{ prompt_tokens }} tokens, Prefix Cache {{ 'ON' if prefix_cache else 'OFF' }}",
  "variables": {
    "VENV_PATH": "{{ infrastructure.venv_path }}",
    "MODEL": "{{ infrastructure.model }}",
    "PORT": "8200",
    "LOG_FILE": "/tmp/vllm_consumer_{{ backend }}_{{ pattern_id }}.log",
    "PID_FILE": "/tmp/vllm_consumer_{{ backend }}_{{ pattern_id }}.pid",
    "GPU_MEMORY_UTIL": "{{ gpu_memory_utilization }}",
    "MAX_BATCHED_TOKENS": "{{ max_num_batched_tokens }}",
    "MAX_MODEL_LEN": "{{ max_model_len }}"{% if infrastructure.tp_size is defined and infrastructure.tp_size > 1 %},
    "TP_SIZE": "{{ infrastructure.tp_size }}"
{% endif %}

  },
  "tasks": [
    {
      "id": "01-cleanup-gpu",
      "name": "Cleanup GPU Memory",
      "description": "Terminate existing vLLM processes",
      "commands": [
        "sudo pkill -9 -f 'vllm.entrypoints' 2>/dev/null || true",
        "sudo pkill -9 -f 'ray::' 2>/dev/null || true",
        "echo '[INFO] Waiting for GPU memory to be released...'",
        "sleep 15",
        "nvidia-smi --query-gpu=index,memory.used --format=csv,noheader || true"
      ]
    },
    {
      "id": "02-start-consumer",
      "name": "Start vLLM Consumer ({{ backend|upper }}, {{ 'Prefix Cache ON' if prefix_cache else 'Prefix Cache OFF' }})",
      "description": "Start Consumer ({{ backend|upper }}, max_model_len={{ max_model_len }})",
      "skip_if": "pgrep -f 'vllm.entrypoints.openai.api_server.*kv_consumer' > /dev/null && curl -s http://localhost:{{"{{"}}PORT{{"}}"}}/health | grep -q ok",
      "commands": [
        "if [ -z \"$NODE2_PRIVATE\" ]; then echo '[ERROR] NODE2_PRIVATE not set'; exit 1; fi",
        "source {{"{{"}}VENV_PATH{{"}}"}}/bin/activate",
{% if infrastructure.tp_size is defined and infrastructure.tp_size > 1 %}
        "export NCCL_DEBUG=INFO",
        "export NCCL_IB_DISABLE=0",
{% endif %}
{% if backend == 'efa' %}
        "export NIXL_BACKEND=LIBFABRIC",
        "export FI_PROVIDER=efa",
        "export FI_EFA_FORK_SAFE=1",
        "export FI_EFA_USE_DEVICE_RDMA=1",
{% elif backend == 'tcp' %}
        "export NIXL_BACKEND=TCP",
{% else %}
        "export NIXL_BACKEND=UCX",
{% endif %}
        "export VLLM_NIXL_SIDE_CHANNEL_HOST=$NODE2_PRIVATE",
        "nohup python -m vllm.entrypoints.openai.api_server --model {{"{{"}}MODEL{{"}}"}} --disable-log-requests --trust-remote-code --port {{"{{"}}PORT{{"}}"}} {% if infrastructure.tp_size is defined and infrastructure.tp_size > 1 %}--tensor-parallel-size {{ tp_per_node }} {% endif %}--gpu-memory-utilization {{"{{"}}GPU_MEMORY_UTIL{{"}}"}} --max-num-batched-tokens {{"{{"}}MAX_BATCHED_TOKENS{{"}}"}} --enable-chunked-prefill --enforce-eager --max-model-len {{"{{"}}MAX_MODEL_LEN{{"}}"}} {{ '--enable-prefix-caching' if prefix_cache else '--no-enable-prefix-caching' }} --kv-transfer-config '{\"kv_connector\":\"NixlConnector\",\"kv_role\":\"kv_consumer\",\"kv_rank\":1,\"kv_parallel_size\":2,\"kv_buffer_device\":\"cuda\",\"kv_buffer_size\":{{ kv_buffer_size }},\"backends\":[\"{% if backend == 'efa' %}LIBFABRIC{% elif backend == 'tcp' %}TCP{% else %}UCX{% endif %}\"]}' > {{"{{"}}LOG_FILE{{"}}"}} 2>&1 &",
        "echo $! > {{"{{"}}PID_FILE{{"}}"}}",
        "echo '[OK] {{ backend|upper }} Consumer started ({{ 'Prefix Cache ON' if prefix_cache else 'Prefix Cache OFF' }})'"
      ]
    },
    {
      "id": "03-wait-initialization",
      "name": "Wait for Consumer Initialization",
      "description": "Wait for model initialization",
      "commands": [
        "echo '[INFO] Waiting {{ init_wait_seconds }} seconds for initialization...'",
        "sleep {{ init_wait_seconds }}"
      ]
    },
    {
      "id": "04-health-check",
      "name": "Consumer Health Check",
      "description": "Verify Consumer server is ready",
      "commands": [
        "for i in $(seq 1 120); do HTTP_CODE=$(curl -s -o /dev/null -w '%{http_code}' http://localhost:{{"{{"}}PORT{{"}}"}}/health 2>/dev/null || echo '000'); if [ \"$HTTP_CODE\" = \"200\" ]; then echo '[OK] Consumer server ready'; exit 0; fi; [ $((i % 20)) -eq 0 ] && echo '[INFO] Waiting... ('$i'/120)'; sleep 1; done; echo '[ERROR] Consumer health check timeout'; cat {{"{{"}}LOG_FILE{{"}}"}} | tail -50; exit 1"
      ]
    }
  ]
}
